## ЛР 0 MatMul Жарков Кирилл Сергеевич 6132-010402D

В данной ЛР выполнена алгоритмса подсчета произведения матриц на CPU и GPU размерностями от 100x100 до 2000x2000.
Выполнено на питоне. Использована библиотека numba для реализации алгоритма на GPU.
Распараллеливание на GPU: в функции gpu_mat_mul используется распараллеливание с помощью CUDA. Каждому элементу результирующей матрицы назначается отдлеьный поток. В функции gpu_calc задается структура сетки и блоков. Задается кол-во потоков в блоке (В моем случае 32x32) и количество блоков, которое расчитывается, чтобы захватить все элементы матрицы.
Каждый поток отвечает за один элемент результирующей матрицы.

# Небольшое отступление - я забыл включить голову, и сначала начал делать умножая поэлементно) Вот прекрасные результаты этого)

![image](https://github.com/user-attachments/assets/8435c32f-6695-4d6a-99af-882751d8d635)

Но потом я решил подумать, и вот результат:

![image](https://github.com/user-attachments/assets/a446f445-5613-488d-9919-b8cacd0b5fe0) 

![image](https://github.com/user-attachments/assets/be18bcf3-c595-421b-8dea-2a92fae78629)

![image](https://github.com/user-attachments/assets/74cf442b-9e37-4b4b-add5-2b1ca86bd5c3)

# Вывод
Для маленькой матрицы (100x100) GPU работает медленнее, чем CPU, ускорения нет.
Начиная с матрицы 400x400, GPU начинает показывать лучшее время, обеспечивая ускорение в 4 раза.
Для матриц 700x700 и 1000x1000 ускорение на GPU увеличивается, достигая 7x и 5x соответственно.
Для больших матриц (2000x2000) GPU демонстрирует значительное ускорение в 33.9 раза, показывая преимущества параллелизации на больших данных
